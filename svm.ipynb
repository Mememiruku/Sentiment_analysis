{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from nltk.corpus import stopwords\n",
    "from time import time \n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = pd.read_csv(\"svmtest.csv\")\n",
    "\n",
    "file_split = file.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cewek',\n",
       " 'lho',\n",
       " 'rasain',\n",
       " 'sibuk',\n",
       " 'jaga',\n",
       " 'rasain',\n",
       " 'sakit',\n",
       " 'haid',\n",
       " 'panik',\n",
       " 'pulang',\n",
       " 'malam',\n",
       " 'gimana',\n",
       " 'orang',\n",
       " 'asing',\n",
       " 'wajar',\n",
       " 'korban',\n",
       " 'takut',\n",
       " 'curhat',\n",
       " 'bela',\n",
       " 'hujat']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tokenized = [[w for w in sentence.split(\" \") if w != \"\"] for sentence in file_split[\"tweet\"]]\n",
    "x_tokenized[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequencer():\n",
    "    \n",
    "    def __init__(self,\n",
    "                 all_words,\n",
    "                 max_words,\n",
    "                 seq_len,\n",
    "                 embedding_matrix\n",
    "                ):\n",
    "        \n",
    "        self.seq_len = seq_len\n",
    "        self.embed_matrix = embedding_matrix\n",
    "        \"\"\"\n",
    "        temp_vocab = Vocab which has all the unique words\n",
    "        self.vocab = Our last vocab which has only most used N words.\n",
    "    \n",
    "        \"\"\"\n",
    "        temp_vocab = list(set(all_words))\n",
    "        self.vocab = []\n",
    "        self.word_cnts = {}\n",
    "        \"\"\"\n",
    "        Now we'll create a hash map (dict) which includes words and their occurencies\n",
    "        \"\"\"\n",
    "        for word in temp_vocab:\n",
    "            # 0 does not have a meaning, you can add the word to the list\n",
    "            # or something different.\n",
    "            count = len([0 for w in all_words if w == word])\n",
    "            self.word_cnts[word] = count\n",
    "            counts = list(self.word_cnts.values())\n",
    "            indexes = list(range(len(counts)))\n",
    "        \n",
    "        # Now we'll sort counts and while sorting them also will sort indexes.\n",
    "        # We'll use those indexes to find most used N word.\n",
    "        cnt = 0\n",
    "        while cnt + 1 != len(counts):\n",
    "            cnt = 0\n",
    "            for i in range(len(counts)-1):\n",
    "                if counts[i] < counts[i+1]:\n",
    "                    counts[i+1],counts[i] = counts[i],counts[i+1]\n",
    "                    indexes[i],indexes[i+1] = indexes[i+1],indexes[i]\n",
    "                else:\n",
    "                    cnt += 1\n",
    "        \n",
    "        for ind in indexes[:max_words]:\n",
    "            self.vocab.append(temp_vocab[ind])\n",
    "                    \n",
    "    def textToVector(self,text):\n",
    "        # First we need to split the text into its tokens and learn the length\n",
    "        # If length is shorter than the max len we'll add some spaces (100D vectors which has only zero values)\n",
    "        # If it's longer than the max len we'll trim from the end.\n",
    "        tokens = text.split()\n",
    "        len_v = len(tokens)-1 if len(tokens) < self.seq_len else self.seq_len-1\n",
    "        vec = []\n",
    "        for tok in tokens[:len_v]:\n",
    "            try:\n",
    "                vec.append(self.embed_matrix[tok])\n",
    "            except Exception as E:\n",
    "                pass\n",
    "        \n",
    "        last_pieces = self.seq_len - len(vec)\n",
    "        for i in range(last_pieces):\n",
    "            vec.append(np.zeros(300,))\n",
    "        \n",
    "        return np.asarray(vec).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 07:02:39: loading Word2Vec object from svmtest.model\n",
      "INFO - 07:02:39: loading wv recursively from svmtest.model.wv.* with mmap=None\n",
      "INFO - 07:02:39: setting ignored attribute cum_table to None\n",
      "INFO - 07:02:39: Word2Vec lifecycle event {'fname': 'svmtest.model', 'datetime': '2023-06-24T07:02:39.288547', 'gensim': '4.3.1', 'python': '3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'loaded'}\n"
     ]
    }
   ],
   "source": [
    "#load the model\n",
    "word_embeddings = Word2Vec.load(\"svmtest.model\").wv\n",
    "\n",
    "sequencer = Sequencer(all_words = [token for seq in x_tokenized for token in seq],\n",
    "              max_words = 1200,\n",
    "              seq_len = 15,\n",
    "              embedding_matrix = word_embeddings\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4398, 4500)\n"
     ]
    }
   ],
   "source": [
    "# But before creating a PCA model using scikit-learn let's create\n",
    "# vectors for our each vector\n",
    "x_vecs = np.asarray([sequencer.textToVector(\" \".join(seq)) for seq in x_tokenized])\n",
    "print(x_vecs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of variance ratios:  0.9717495765777076\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca_model = PCA(n_components=1000)\n",
    "pca_model.fit(x_vecs)\n",
    "print(\"Sum of variance ratios: \",sum(pca_model.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4398, 1000)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_comps = pca_model.transform(x_vecs)\n",
    "x_comps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3518, 1000)\n",
      "(880, 1000)\n",
      "(3518,)\n",
      "(880,)\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x_comps,file_split['label'],test_size=0.2,random_state=42)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine Classifier has fitted, this process took 2.62 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time() \n",
    "\n",
    "svm_classifier = SVC()\n",
    "svm_classifier.fit(x_train,y_train)\n",
    "\n",
    "end = time.time()\n",
    "process = round(end-start,2)\n",
    "print(\"Support Vector Machine Classifier has fitted, this process took {} seconds\".format(process))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of SVM Classifier\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>490</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>125</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  490   63\n",
       "1  125  202"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " Scores of SVM Classifier\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.786364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.762264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.617737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.682432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             scores\n",
       "accuracy   0.786364\n",
       "precision  0.762264\n",
       "recall     0.617737\n",
       "f1         0.682432"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "predicted_classes = svm_classifier.predict(x_test)\n",
    "conf_matrix = pd.DataFrame(confusion_matrix(y_test, predicted_classes))\n",
    "print('Confusion Matrix of SVM Classifier')\n",
    "display(conf_matrix)\n",
    "\n",
    "test_scores = accuracy_score(y_test,predicted_classes), precision_score(y_test, predicted_classes), recall_score(y_test, predicted_classes), f1_score(y_test, predicted_classes)\n",
    "\n",
    "print('\\n \\n Scores of SVM Classifier')\n",
    "scores = pd.DataFrame(data=[test_scores])\n",
    "scores.columns = ['accuracy', 'precision', 'recall', 'f1']\n",
    "scores = scores.T\n",
    "scores.columns = ['scores']\n",
    "display(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes has fitted, this process took 0.04 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB,BernoulliNB\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(x_train,y_train)\n",
    "\n",
    "end = time.time()\n",
    "process = round(end-start,2)\n",
    "print(\"Gaussian Naive Bayes has fitted, this process took {} seconds\".format(process))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes has fitted, this process took 0.06 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(x_train,y_train)\n",
    "\n",
    "end = time.time()\n",
    "process = round(end-start,2)\n",
    "print(\"Bernoulli Naive Bayes has fitted, this process took {} seconds\".format(process))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of Gaussian Naive Bayes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>304</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>159</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  304  249\n",
       "1  159  168"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " Scores of Gaussian Naive Bayes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.536364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.402878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.513761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.451613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             scores\n",
       "accuracy   0.536364\n",
       "precision  0.402878\n",
       "recall     0.513761\n",
       "f1         0.451613"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of Bernoulli Naive Bayes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>447</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>174</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  447  106\n",
       "1  174  153"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " Scores of Bernoulli Naive Bayes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.681818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.590734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.467890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.522184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             scores\n",
       "accuracy   0.681818\n",
       "precision  0.590734\n",
       "recall     0.467890\n",
       "f1         0.522184"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gnb_prediction = gnb.predict(x_test)\n",
    "conf_matrix = pd.DataFrame(confusion_matrix(y_test, gnb_prediction))\n",
    "print('Confusion Matrix of Gaussian Naive Bayes')\n",
    "display(conf_matrix)\n",
    "\n",
    "gnb_test_scores = accuracy_score(y_test,gnb_prediction), precision_score(y_test, gnb_prediction), recall_score(y_test, gnb_prediction), f1_score(y_test, gnb_prediction)\n",
    "\n",
    "print('\\n \\n Scores of Gaussian Naive Bayes')\n",
    "scores = pd.DataFrame(data=[gnb_test_scores])\n",
    "scores.columns = ['accuracy', 'precision', 'recall', 'f1']\n",
    "scores = scores.T\n",
    "scores.columns = ['scores']\n",
    "display(scores)\n",
    "\n",
    "\n",
    "bnb_prediction = bnb.predict(x_test)\n",
    "conf_matrix = pd.DataFrame(confusion_matrix(y_test, bnb_prediction))\n",
    "print('Confusion Matrix of Bernoulli Naive Bayes')\n",
    "display(conf_matrix)\n",
    "\n",
    "bnb_test_scores = accuracy_score(y_test,bnb_prediction), precision_score(y_test, bnb_prediction), recall_score(y_test, bnb_prediction), f1_score(y_test, bnb_prediction)\n",
    "\n",
    "print('\\n \\n Scores of Bernoulli Naive Bayes')\n",
    "scores = pd.DataFrame(data=[bnb_test_scores])\n",
    "scores.columns = ['accuracy', 'precision', 'recall', 'f1']\n",
    "scores = scores.T\n",
    "scores.columns = ['scores']\n",
    "display(scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
