{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "\n",
    "from re import sub\n",
    "from time import time \n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_word_list(text):\n",
    "    text = text.split()\n",
    "\n",
    "    return text  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = pd.read_csv(\"Cleaned_dataset.csv\")\n",
    "\n",
    "file_split = file.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_split.tweet = file_split.tweet.apply(lambda x: text_to_word_list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       [soal, jalan, jatibaru, polisi, tidak, bisa, g...\n",
      "1       [sama, cewek, lho, kayak, harus, bisa, lebih, ...\n",
      "2       [kepingin, gudeg, mbarek, bu, hj, amad, foto, ...\n",
      "3       [jalan, jatibaru, bagi, dari, wilayah, tn, aba...\n",
      "4       [sharing, alam, aja, kemarin, jam, 18, 00, bat...\n",
      "                              ...                        \n",
      "4396    [tahu, kamu, bahwa, saat, itu, papa, mejam, ma...\n",
      "4397    [sulit, tetap, calon, wapresnya, jokowi, di, p...\n",
      "4398    [5, masa, depan, tidak, jelas, lha, iya, giman...\n",
      "4399    [dulu, benar, ada, mahasiswa, teknik, ui, nemb...\n",
      "4400    [ya, allah, hanya, engkau, yang, tahu, rasa, s...\n",
      "Name: tweet, Length: 4401, dtype: object\n"
     ]
    }
   ],
   "source": [
    "file_model = file_split.copy()\n",
    "file_model = file_model[file_model.tweet.str.len()>1]\n",
    "print(file_model['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 16:20:40: collecting all words and their counts\n",
      "INFO - 16:20:40: PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "INFO - 16:20:40: collected 95602 token types (unigram + bigrams) from a corpus of 123605 words and 4401 sentences\n",
      "INFO - 16:20:40: merged Phrases<95602 vocab, min_count=1, threshold=10.0, max_vocab_size=40000000>\n",
      "INFO - 16:20:40: Phrases lifecycle event {'msg': 'built Phrases<95602 vocab, min_count=1, threshold=10.0, max_vocab_size=40000000> in 0.08s', 'datetime': '2023-06-22T16:20:40.112368', 'gensim': '4.3.1', 'python': '3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'created'}\n",
      "INFO - 16:20:40: exporting phrases from Phrases<95602 vocab, min_count=1, threshold=10.0, max_vocab_size=40000000>\n",
      "INFO - 16:20:40: FrozenPhrases lifecycle event {'msg': 'exported FrozenPhrases<4165 phrases, min_count=1, threshold=10.0> from Phrases<95602 vocab, min_count=1, threshold=10.0, max_vocab_size=40000000> in 0.07s', 'datetime': '2023-06-22T16:20:40.185368', 'gensim': '4.3.1', 'python': '3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'created'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['soal',\n",
       " 'jalan_jatibaru',\n",
       " 'polisi',\n",
       " 'tidak',\n",
       " 'bisa',\n",
       " 'gertak',\n",
       " 'gubernur',\n",
       " 'emangny',\n",
       " 'polisi',\n",
       " 'tidak',\n",
       " 'ikut',\n",
       " 'pmbhasan',\n",
       " 'jangan',\n",
       " 'politik',\n",
       " 'atur_wilayah',\n",
       " 'hak',\n",
       " 'gubernur',\n",
       " 'soal',\n",
       " 'tn_abang',\n",
       " 'soal',\n",
       " 'turun',\n",
       " 'turun',\n",
       " 'pelik',\n",
       " 'perlu',\n",
       " 'sabar']"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = [row for row in file_model.tweet]\n",
    "phrases = Phrases(sent, min_count=1, progress_per=50000)\n",
    "bigram = Phraser(phrases)\n",
    "sentences = bigram[sent]\n",
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 16:20:40: Word2Vec lifecycle event {'params': 'Word2Vec<vocab=0, vector_size=100, alpha=0.03>', 'datetime': '2023-06-22T16:20:40.192368', 'gensim': '4.3.1', 'python': '3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'created'}\n",
      "INFO - 16:20:40: collecting all words and their counts\n",
      "INFO - 16:20:40: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 16:20:40: collected 17294 word types from a corpus of 111917 raw words and 4401 sentences\n",
      "INFO - 16:20:40: Creating a fresh vocabulary\n",
      "INFO - 16:20:40: Word2Vec lifecycle event {'msg': 'effective_min_count=2 retains 8710 unique words (50.36% of original 17294, drops 8584)', 'datetime': '2023-06-22T16:20:40.271368', 'gensim': '4.3.1', 'python': '3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'prepare_vocab'}\n",
      "INFO - 16:20:40: Word2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 103333 word corpus (92.33% of original 111917, drops 8584)', 'datetime': '2023-06-22T16:20:40.272368', 'gensim': '4.3.1', 'python': '3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'prepare_vocab'}\n",
      "INFO - 16:20:40: deleting the raw counts dictionary of 17294 items\n",
      "INFO - 16:20:40: sample=1e-05 downsamples 4672 most-common words\n",
      "INFO - 16:20:40: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 28122.137617066313 word corpus (27.2%% of prior 103333)', 'datetime': '2023-06-22T16:20:40.299368', 'gensim': '4.3.1', 'python': '3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'prepare_vocab'}\n",
      "INFO - 16:20:40: estimated required memory for 8710 words and 100 dimensions: 11323000 bytes\n",
      "INFO - 16:20:40: resetting layer weights\n",
      "INFO - 16:20:40: Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-06-22T16:20:40.334368', 'gensim': '4.3.1', 'python': '3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'build_vocab'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build vocab: 0.0 mins\n"
     ]
    }
   ],
   "source": [
    "w2v_model = Word2Vec(min_count=2,\n",
    "                     window=4,\n",
    "                     vector_size=100,\n",
    "                     sample=1e-5, \n",
    "                     alpha=0.03, \n",
    "                     min_alpha=0.0007, \n",
    "                     negative=20,\n",
    "                     workers=multiprocessing.cpu_count()-1)\n",
    "\n",
    "start = time()\n",
    "\n",
    "w2v_model.build_vocab(sentences, progress_per=50000)\n",
    "\n",
    "print('Time to build vocab: {} mins'.format(round((time() - start) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 16:20:40: Word2Vec lifecycle event {'msg': 'training model with 11 workers on 8710 vocabulary and 100 features, using sg=0 hs=0 sample=1e-05 negative=20 window=4 shrink_windows=True', 'datetime': '2023-06-22T16:20:40.339393', 'gensim': '4.3.1', 'python': '3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'train'}\n",
      "INFO - 16:20:40: EPOCH 0: training on 111917 raw words (28049 effective words) took 0.1s, 460993 effective words/s\n",
      "INFO - 16:20:40: EPOCH 1: training on 111917 raw words (28187 effective words) took 0.1s, 444144 effective words/s\n",
      "INFO - 16:20:40: EPOCH 2: training on 111917 raw words (28075 effective words) took 0.1s, 424081 effective words/s\n",
      "INFO - 16:20:40: EPOCH 3: training on 111917 raw words (28271 effective words) took 0.1s, 444319 effective words/s\n",
      "INFO - 16:20:40: EPOCH 4: training on 111917 raw words (28154 effective words) took 0.1s, 429487 effective words/s\n",
      "INFO - 16:20:40: EPOCH 5: training on 111917 raw words (28289 effective words) took 0.1s, 424815 effective words/s\n",
      "INFO - 16:20:40: EPOCH 6: training on 111917 raw words (28094 effective words) took 0.1s, 429611 effective words/s\n",
      "INFO - 16:20:40: EPOCH 7: training on 111917 raw words (27958 effective words) took 0.1s, 402561 effective words/s\n",
      "INFO - 16:20:41: EPOCH 8: training on 111917 raw words (28236 effective words) took 0.1s, 513739 effective words/s\n",
      "INFO - 16:20:41: EPOCH 9: training on 111917 raw words (28156 effective words) took 0.1s, 527015 effective words/s\n",
      "INFO - 16:20:41: EPOCH 10: training on 111917 raw words (27968 effective words) took 0.0s, 859678 effective words/s\n",
      "INFO - 16:20:41: EPOCH 11: training on 111917 raw words (28127 effective words) took 0.1s, 417932 effective words/s\n",
      "INFO - 16:20:41: EPOCH 12: training on 111917 raw words (28201 effective words) took 0.1s, 415205 effective words/s\n",
      "INFO - 16:20:41: EPOCH 13: training on 111917 raw words (28003 effective words) took 0.0s, 825383 effective words/s\n",
      "INFO - 16:20:41: EPOCH 14: training on 111917 raw words (28021 effective words) took 0.1s, 433274 effective words/s\n",
      "INFO - 16:20:41: EPOCH 15: training on 111917 raw words (27962 effective words) took 0.1s, 413115 effective words/s\n",
      "INFO - 16:20:41: EPOCH 16: training on 111917 raw words (28139 effective words) took 0.1s, 406944 effective words/s\n",
      "INFO - 16:20:41: EPOCH 17: training on 111917 raw words (28087 effective words) took 0.1s, 422176 effective words/s\n",
      "INFO - 16:20:41: EPOCH 18: training on 111917 raw words (28043 effective words) took 0.1s, 409643 effective words/s\n",
      "INFO - 16:20:41: EPOCH 19: training on 111917 raw words (28090 effective words) took 0.1s, 408260 effective words/s\n",
      "INFO - 16:20:42: EPOCH 20: training on 111917 raw words (28156 effective words) took 0.1s, 493624 effective words/s\n",
      "INFO - 16:20:42: EPOCH 21: training on 111917 raw words (28104 effective words) took 0.1s, 494476 effective words/s\n",
      "INFO - 16:20:42: EPOCH 22: training on 111917 raw words (28025 effective words) took 0.0s, 1060653 effective words/s\n",
      "INFO - 16:20:42: EPOCH 23: training on 111917 raw words (28209 effective words) took 0.0s, 642277 effective words/s\n",
      "INFO - 16:20:42: EPOCH 24: training on 111917 raw words (28072 effective words) took 0.1s, 479172 effective words/s\n",
      "INFO - 16:20:42: EPOCH 25: training on 111917 raw words (28238 effective words) took 0.0s, 574138 effective words/s\n",
      "INFO - 16:20:42: EPOCH 26: training on 111917 raw words (27905 effective words) took 0.1s, 421649 effective words/s\n",
      "INFO - 16:20:42: EPOCH 27: training on 111917 raw words (28093 effective words) took 0.1s, 386079 effective words/s\n",
      "INFO - 16:20:42: EPOCH 28: training on 111917 raw words (28107 effective words) took 0.1s, 290267 effective words/s\n",
      "INFO - 16:20:42: EPOCH 29: training on 111917 raw words (28238 effective words) took 0.1s, 433863 effective words/s\n",
      "INFO - 16:20:42: EPOCH 30: training on 111917 raw words (28020 effective words) took 0.1s, 430862 effective words/s\n",
      "INFO - 16:20:42: EPOCH 31: training on 111917 raw words (28043 effective words) took 0.1s, 431557 effective words/s\n",
      "INFO - 16:20:43: EPOCH 32: training on 111917 raw words (28082 effective words) took 0.1s, 432602 effective words/s\n",
      "INFO - 16:20:43: EPOCH 33: training on 111917 raw words (28168 effective words) took 0.1s, 422328 effective words/s\n",
      "INFO - 16:20:43: EPOCH 34: training on 111917 raw words (28023 effective words) took 0.0s, 654893 effective words/s\n",
      "INFO - 16:20:43: EPOCH 35: training on 111917 raw words (27919 effective words) took 0.1s, 419964 effective words/s\n",
      "INFO - 16:20:43: EPOCH 36: training on 111917 raw words (27954 effective words) took 0.1s, 411331 effective words/s\n",
      "INFO - 16:20:43: EPOCH 37: training on 111917 raw words (28096 effective words) took 0.1s, 412433 effective words/s\n",
      "INFO - 16:20:43: EPOCH 38: training on 111917 raw words (28188 effective words) took 0.0s, 713991 effective words/s\n",
      "INFO - 16:20:43: EPOCH 39: training on 111917 raw words (27837 effective words) took 0.1s, 509968 effective words/s\n",
      "INFO - 16:20:43: EPOCH 40: training on 111917 raw words (28039 effective words) took 0.1s, 521514 effective words/s\n",
      "INFO - 16:20:43: EPOCH 41: training on 111917 raw words (28122 effective words) took 0.1s, 462563 effective words/s\n",
      "INFO - 16:20:43: EPOCH 42: training on 111917 raw words (28091 effective words) took 0.1s, 455329 effective words/s\n",
      "INFO - 16:20:43: EPOCH 43: training on 111917 raw words (28025 effective words) took 0.1s, 394398 effective words/s\n",
      "INFO - 16:20:43: EPOCH 44: training on 111917 raw words (28268 effective words) took 0.1s, 394844 effective words/s\n",
      "INFO - 16:20:44: EPOCH 45: training on 111917 raw words (28214 effective words) took 0.1s, 511817 effective words/s\n",
      "INFO - 16:20:44: EPOCH 46: training on 111917 raw words (28078 effective words) took 0.1s, 511150 effective words/s\n",
      "INFO - 16:20:44: EPOCH 47: training on 111917 raw words (28142 effective words) took 0.1s, 495255 effective words/s\n",
      "INFO - 16:20:44: EPOCH 48: training on 111917 raw words (28100 effective words) took 0.1s, 480635 effective words/s\n",
      "INFO - 16:20:44: EPOCH 49: training on 111917 raw words (28083 effective words) took 0.0s, 641178 effective words/s\n",
      "INFO - 16:20:44: Word2Vec lifecycle event {'msg': 'training on 5595850 raw words (1404749 effective words) took 4.0s, 347552 effective words/s', 'datetime': '2023-06-22T16:20:44.382439', 'gensim': '4.3.1', 'python': '3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'train'}\n",
      "C:\\Users\\Emerald\\AppData\\Local\\Temp\\ipykernel_1452\\20000913.py:7: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
      "  w2v_model.init_sims(replace=True)\n",
      "WARNING - 16:20:44: destructive init_sims(replace=True) deprecated & no longer required for space-efficiency\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model: 0.07 mins\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=50, report_delay=1)\n",
    "\n",
    "print('Time to train the model: {} mins'.format(round((time() - start) / 60, 2)))\n",
    "\n",
    "w2v_model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 16:20:44: Word2Vec lifecycle event {'fname_or_handle': 'word2vec.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2023-06-22T16:20:44.387406', 'gensim': '4.3.1', 'python': '3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'saving'}\n",
      "INFO - 16:20:44: not storing attribute cum_table\n",
      "INFO - 16:20:44: saved word2vec.model\n"
     ]
    }
   ],
   "source": [
    "w2v_model.save(\"word2vec.model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
